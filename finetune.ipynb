{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uo-XMuZ5_GxG",
    "outputId": "3bec23e3-4a6d-46b3-ecfd-bb97ff0034f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TR7ziAjKAYve",
    "outputId": "1e343121-bd9f-4344-e8c9-f22fa8a1d798"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.6' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '\"c:/Users/vinayak  dixit/AppData/Local/Programs/Python/Python312/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365,
     "referenced_widgets": [
      "b11bceac074340aabeb5f4b3ebf8f318",
      "5988bfb31b194e8084f402eca11342b1",
      "11f5bf6116aa469fbfea38b091e05591",
      "e0b28a3df0f049519b4ce0b94c24a7b1",
      "07551e47141948ba887c09e74e4636c9",
      "8ef3827561e046bd956e57bd8e362a54",
      "b0abebbac305457383000277ab93123a",
      "55c62cb4ce3142e28a9b58cf0becc40c",
      "1bc5da24abb844eea4b7e27d1a45709f",
      "6d849ad2d1a24442aa19cf6d3ac29962",
      "53cb950571ab48ac95147ea7f3d15dea",
      "41e4ef7a060f4687831118da1de5f5ee",
      "db99a93abda44be8859ed9ac5a714a27",
      "0b8c06579ba04d9f84529abf2d4df112",
      "ffa685e5a7a541b492d118f73f381970",
      "687e028a288b40c1a78f73d7317dc914",
      "6410fe17a322419ea4ec0b52393efcf7",
      "3cdd92fde0fa42aeb97f22d60f5d3c39",
      "499d7f036c394ee1b1c7beba97fd170c",
      "5df02a9cd5a0426aa980803e333fa523",
      "fc4d71e2498849b69e5bfa3bee3ba10d",
      "5fc07a0f3eea4852a22b342c99788fca",
      "4f34f78a891545b8a2ce38a9843751d7",
      "15683b6145d44397849077d329e09991",
      "0acfaa0cde364772abda5a0aab54af59",
      "0b535c19cce24c2ba7fc9ad2a8c540c4",
      "da5d7a440f5b4ec5b33461b3596b6d24",
      "c805c3b5ab4b4105a13ed2b928044863",
      "723a9a8fd62d48d48343e23972be28cf",
      "7573615f0ce442f49adfbf86bdc16949",
      "1f42fb789eda4b91a665fb280c022871",
      "ee20aca320764be0af15073943b0ec4e",
      "582ca8cef70d413ea4689842cf0731b4",
      "2f8341444a254555a72a0631669accae",
      "b3a8dad217e14baf9e0d361dbc8d4b09",
      "830b1d6c81404bc7accb04cb560a51eb",
      "48a51215dea34000b88c0aa5b48bdfd0",
      "0ec5d3ac86e94d29aae06d9518c62ff5",
      "0dd02a90fa5a40a292a30b9a7f1efe59",
      "114b5df40fac422fa649a17d46f7c790",
      "3f4102743e764916a6d33381a61fdcf7",
      "631c530dd4c6419292ffc52c7ea181d9",
      "f912543777284552a591f3b38d86c8d0",
      "77c47f2c4c0b4075b7c9b4bedf7e196f",
      "399bb34e9f18410594bfcc2df03f60d3",
      "c81bcae73e184544bd8e30dcd8208e10",
      "c880081a731045649252d35d733397a6",
      "ae8675ff1e8c4658bf8fe0f1fd25263a",
      "4c14c42340fc47cfab54a253723f9ae3",
      "4387956c7fea4b69b071d95ffce2d364",
      "f4dae56e79124e3bbd558c1cab64f8d0",
      "e19f5a74cebd4fed863b3eac627468cd",
      "88e6fafedbb147088a518d0285de9634",
      "4ef552881a734db39bb439565914096c",
      "09194d4447584f9d9c07885cf1a22ce0",
      "d94fcef6453b417b82f4eff9734b99c4",
      "03bf0c19f48346619d92c63c63e42600",
      "7cc69fddaff14c68aaa713c4c23fc690",
      "463d94856d7b4377a520c500e92656b8",
      "3ad79bd5807449cc9536483c112d6210",
      "9080fe3fac89489cb8acdd9c7ce0a52d",
      "fca1a783eb30428b937debe2188e2ca9",
      "f2a98bb8e9524a3f968550b0aeed9cd4",
      "806df02969af4c4bbcd352a0190a27fa",
      "7f61282d1dc44bc28cebab43f5fdff5d",
      "74ab4e56a064442ea650c606bb87cbd3",
      "25f4da1728294976aceeb88c14e60d19",
      "11f6de70d2b94d63b494126c48c7da83",
      "0d56a598acb0424b93ba45c0cdafaa98",
      "73978ec445c048d9b45b8be4b189e780",
      "03a73dd2fb334d549240cd9cf6ef5a7b",
      "7ccc1217a30949ebaaf2ec7ddd0cd6e4",
      "04bb55723db54fe5aa1590e523e8f8ba",
      "c8fe9625212f48baa0bbb01e18bab3dd",
      "0e1f8209f01f4148a704c4156eb3af4b",
      "b4d90777eb484055a009eec4ac394dcf",
      "5523f4b41bd8425ab9bd2c6ab613f599"
     ]
    },
    "id": "PJEXUNQVAk_7",
    "outputId": "8788fe7d-5247-4dd8-c066-426bede963d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11bceac074340aabeb5f4b3ebf8f318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e4ef7a060f4687831118da1de5f5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f34f78a891545b8a2ce38a9843751d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8341444a254555a72a0631669accae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/unsupervised-00000-of-00001.p(â€¦):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "399bb34e9f18410594bfcc2df03f60d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94fcef6453b417b82f4eff9734b99c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f4da1728294976aceeb88c14e60d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset= load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ky0cXxlIBhXo",
    "outputId": "68e5112f-03d0-4fa4-ee94-9ead5a4f6d81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Juj_FOOUBuJa",
    "outputId": "c29afa57-efe0-410a-bfec-f23ebd755e01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "e90c6637298e4c159409a404cc6ba91b",
      "8329940fcb9c42ea93f890bcf1634057",
      "59e52882066842e487abd26823904c9f",
      "be8d2fbc297144a1b19cf09ac97e42b8",
      "a525e22364e6446b84a494f3ce4ea40d",
      "dfcf1793f7cc4d5dbe0cdec54b61c53f",
      "8b4789ae0d074e1b86832519b837dbff",
      "4cdf5dd52364447cbf0bca69f8dd52f0",
      "11131a16c27149d3af047521f3c35c00",
      "22f1e3ba191844a986d407854737b5f9",
      "c65acfa742534379b3c263defdd1ed25",
      "859175072cee4b2ba364315896a868b0",
      "81077cfc655843a4908b2dee63db9d17",
      "d7dab27eecf041889716eea2fb17388a",
      "a41976dd57a1405ebd10b70de941f5e4",
      "5db9053412404f81bbd0554560b2da54",
      "f09b4d2a4a274f06a4f08803bada48af",
      "02665e849ec1455789b13ac68979abd2",
      "95a81835f50848088539fd8eca493608",
      "9403826019a548a6af2d8f6e1b4a5625",
      "d4eaae03b8d84bd6b1eba16d0b81bad6",
      "64f12df792e442ccbc04197250eef37d",
      "0a7841c9ef424f5c9a2247f1d41699aa",
      "bbef9fe826ba4ede8f13cbd193aabaa3",
      "18b78dee379946eba67cbeb3033e246f",
      "b36a2b1e28874c51988e4baa279aff85",
      "f86ebc216e3f46c38b19f7b36369bc1a",
      "4f5e73126cf14c81bcd1fb3638885aa5",
      "7631df5b34974cabb2cc05f35e387463",
      "42ab9c22e8114519b94dfc2c5ca9405c",
      "d1ea778f50824f8ba420c1bfb5fd81ca",
      "cc9f01e4d3814f2bb737086d42818677",
      "93a170af6cc34e8ea46c0b7745bfe9ad",
      "a3e896801f124e569fac2a096247f9b3",
      "3c3270a41c534df0a0bd4d530054cbe6",
      "a922b0f84ef74ae58e1122d5f4614d0f",
      "eedd7e9cfcec47c18c4f16f7f45b7ae1",
      "d6f1ba5ba7774e138726c9331bd2282f",
      "3959c944b9df4eadac243fcedb0c9abf",
      "dfd057da77fd4cbab7bf0d6e5eccc0d2",
      "16e654d118ff416381c6caf616d837f6",
      "b66547febbf74e019b80255898727bcc",
      "4f6af09458cb4de0bfc0342b2a921254",
      "08ac8ee3d81f479b8ef3448299b809e8"
     ]
    },
    "id": "VEIrLMapCJGI",
    "outputId": "6ce7f56c-fc64-44bc-a93a-819d629ddea0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90c6637298e4c159409a404cc6ba91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859175072cee4b2ba364315896a868b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7841c9ef424f5c9a2247f1d41699aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e896801f124e569fac2a096247f9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer= AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "5421249d79884342a161e850baa0b181",
      "31ebd3545bdc40fe86102d363af60d02",
      "0c624eee705247f0abad7ad3f549e54a",
      "cc4c0310e024405f99c8a322d0f2d489",
      "9f1bc005f3534f11b8ec8f4f809eb1ff",
      "15f3a8a0f81947b2bb20eafb081561b6",
      "816e73aceead4895baae0db87b898cd9",
      "176ab91296854288b383dbfae56c8f4e",
      "1dee9c19546a445e8198c8bb570d6e0a",
      "6d82fecf8092448d97973645b8eca164",
      "1259771bf6614bf7af8749b81c551e04",
      "9adab2755c5c4aa48d42f4bde08b0eed",
      "fd125274b37f457b9bf29e0d6481f112",
      "f1b99507a1e843938bb0b83cf4ef9867",
      "0dff831e147b4b82be9094e0cc3a3220",
      "e3feebcc899c4acd8375bf5fa75f57bd",
      "78bcc41233c44cbb8764abb107aa5d31",
      "90f03b453e2d41118f5b00719719c80a",
      "86fcbcb195d04955b99f0e332de15b60",
      "f8cfd5a5a0fa474ea7e79ac7975fcf4c",
      "d9d26694bcb1414db56a87864d9e8b2e",
      "d8fd4eb161fc4a3a876bb4c173244536",
      "57a9257567284264be519a04aa473b98",
      "a3d4ef5d1e1b48e9bc0edb8e2e7a84c9",
      "69cd0038ecbb4b3ba52cfedb06aaf5a0",
      "1f99bfc478754f88b1c12917e2f4fc99",
      "6feb33a18c6d40759e8ad3328b26270a",
      "0a725a6b91ff4d1ab6c099a2962caed1",
      "a72f09549e2f46079432356182cfe853",
      "2a7aab79cbef4db2aa0a58324666515b",
      "b7884c22d0dc43378f7e17519137bf94",
      "64b08580c7f34cbaa7559fc044ded9d9",
      "a08d0f25c1054c76a591a6ef836beee6"
     ]
    },
    "id": "enrrD8CACa3E",
    "outputId": "d780727a-77f6-4056-8153-cb5ab7b91ee0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5421249d79884342a161e850baa0b181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adab2755c5c4aa48d42f4bde08b0eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a9257567284264be519a04aa473b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "  return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "\n",
    "tokenized_datasets= dataset.map(tokenize_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "T0bWAbMFDVLg",
    "outputId": "8da28842-3b9b-4e36-9ca0-d71bc2dcb633"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2875078991.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenized_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTCacadMEFAe",
    "outputId": "e0a81e6b-2be7-4197-de2a-a77077545b95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0,\n",
       " 'input_ids': [101,\n",
       "  146,\n",
       "  12765,\n",
       "  146,\n",
       "  6586,\n",
       "  140,\n",
       "  19556,\n",
       "  19368,\n",
       "  13329,\n",
       "  118,\n",
       "  162,\n",
       "  21678,\n",
       "  2162,\n",
       "  17056,\n",
       "  1121,\n",
       "  1139,\n",
       "  1888,\n",
       "  2984,\n",
       "  1272,\n",
       "  1104,\n",
       "  1155,\n",
       "  1103,\n",
       "  6392,\n",
       "  1115,\n",
       "  4405,\n",
       "  1122,\n",
       "  1165,\n",
       "  1122,\n",
       "  1108,\n",
       "  1148,\n",
       "  1308,\n",
       "  1107,\n",
       "  2573,\n",
       "  119,\n",
       "  146,\n",
       "  1145,\n",
       "  1767,\n",
       "  1115,\n",
       "  1120,\n",
       "  1148,\n",
       "  1122,\n",
       "  1108,\n",
       "  7842,\n",
       "  1118,\n",
       "  158,\n",
       "  119,\n",
       "  156,\n",
       "  119,\n",
       "  10148,\n",
       "  1191,\n",
       "  1122,\n",
       "  1518,\n",
       "  1793,\n",
       "  1106,\n",
       "  3873,\n",
       "  1142,\n",
       "  1583,\n",
       "  117,\n",
       "  3335,\n",
       "  1217,\n",
       "  170,\n",
       "  5442,\n",
       "  1104,\n",
       "  2441,\n",
       "  1737,\n",
       "  107,\n",
       "  6241,\n",
       "  107,\n",
       "  146,\n",
       "  1541,\n",
       "  1125,\n",
       "  1106,\n",
       "  1267,\n",
       "  1142,\n",
       "  1111,\n",
       "  1991,\n",
       "  119,\n",
       "  133,\n",
       "  9304,\n",
       "  120,\n",
       "  135,\n",
       "  133,\n",
       "  9304,\n",
       "  120,\n",
       "  135,\n",
       "  1109,\n",
       "  4928,\n",
       "  1110,\n",
       "  8663,\n",
       "  1213,\n",
       "  170,\n",
       "  1685,\n",
       "  3619,\n",
       "  3362,\n",
       "  2377,\n",
       "  1417,\n",
       "  14960,\n",
       "  1150,\n",
       "  3349,\n",
       "  1106,\n",
       "  3858,\n",
       "  1917,\n",
       "  1131,\n",
       "  1169,\n",
       "  1164,\n",
       "  1297,\n",
       "  119,\n",
       "  1130,\n",
       "  2440,\n",
       "  1131,\n",
       "  3349,\n",
       "  1106,\n",
       "  2817,\n",
       "  1123,\n",
       "  2209,\n",
       "  1116,\n",
       "  1106,\n",
       "  1543,\n",
       "  1199,\n",
       "  3271,\n",
       "  1104,\n",
       "  4148,\n",
       "  1113,\n",
       "  1184,\n",
       "  1103,\n",
       "  1903,\n",
       "  156,\n",
       "  11547,\n",
       "  1162,\n",
       "  1354,\n",
       "  1164,\n",
       "  2218,\n",
       "  1741,\n",
       "  2492,\n",
       "  1216,\n",
       "  1112,\n",
       "  1103,\n",
       "  4357,\n",
       "  1414,\n",
       "  1105,\n",
       "  1886,\n",
       "  2492,\n",
       "  1107,\n",
       "  1103,\n",
       "  1244,\n",
       "  1311,\n",
       "  119,\n",
       "  1130,\n",
       "  1206,\n",
       "  4107,\n",
       "  8673,\n",
       "  1105,\n",
       "  6655,\n",
       "  10552,\n",
       "  3708,\n",
       "  2316,\n",
       "  1104,\n",
       "  8583,\n",
       "  1164,\n",
       "  1147,\n",
       "  11089,\n",
       "  1113,\n",
       "  4039,\n",
       "  117,\n",
       "  1131,\n",
       "  1144,\n",
       "  2673,\n",
       "  1114,\n",
       "  1123,\n",
       "  3362,\n",
       "  3218,\n",
       "  117,\n",
       "  22150,\n",
       "  117,\n",
       "  1105,\n",
       "  1597,\n",
       "  1441,\n",
       "  119,\n",
       "  133,\n",
       "  9304,\n",
       "  120,\n",
       "  135,\n",
       "  133,\n",
       "  9304,\n",
       "  120,\n",
       "  135,\n",
       "  1327,\n",
       "  8567,\n",
       "  1143,\n",
       "  1164,\n",
       "  146,\n",
       "  6586,\n",
       "  140,\n",
       "  19556,\n",
       "  19368,\n",
       "  13329,\n",
       "  118,\n",
       "  162,\n",
       "  21678,\n",
       "  2162,\n",
       "  17056,\n",
       "  1110,\n",
       "  1115,\n",
       "  1969,\n",
       "  1201,\n",
       "  2403,\n",
       "  117,\n",
       "  1142,\n",
       "  1108,\n",
       "  1737,\n",
       "  185,\n",
       "  8456,\n",
       "  9597,\n",
       "  119,\n",
       "  8762,\n",
       "  117,\n",
       "  1103,\n",
       "  2673,\n",
       "  1105,\n",
       "  183,\n",
       "  17294,\n",
       "  2340,\n",
       "  4429,\n",
       "  1132,\n",
       "  1374,\n",
       "  1105,\n",
       "  1677,\n",
       "  1206,\n",
       "  117,\n",
       "  1256,\n",
       "  1173,\n",
       "  1122,\n",
       "  112,\n",
       "  188,\n",
       "  1136,\n",
       "  2046,\n",
       "  1176,\n",
       "  1199,\n",
       "  10928,\n",
       "  1193,\n",
       "  1189,\n",
       "  185,\n",
       "  8456,\n",
       "  1186,\n",
       "  119,\n",
       "  1799,\n",
       "  1139,\n",
       "  1583,\n",
       "  2354,\n",
       "  1713,\n",
       "  1525,\n",
       "  1122,\n",
       "  19196,\n",
       "  117,\n",
       "  1107,\n",
       "  3958,\n",
       "  2673,\n",
       "  1105,\n",
       "  183,\n",
       "  17294,\n",
       "  2340,\n",
       "  1132,\n",
       "  170,\n",
       "  1558,\n",
       "  22088,\n",
       "  1107,\n",
       "  3619,\n",
       "  7678,\n",
       "  119,\n",
       "  2431,\n",
       "  1130,\n",
       "  14721,\n",
       "  1197,\n",
       "  27644,\n",
       "  117,\n",
       "  18271,\n",
       "  1147,\n",
       "  2590,\n",
       "  1106,\n",
       "  1363,\n",
       "  1385,\n",
       "  2298,\n",
       "  1287,\n",
       "  4100,\n",
       "  117,\n",
       "  1125,\n",
       "  2673,\n",
       "  4429,\n",
       "  1107,\n",
       "  1117,\n",
       "  2441,\n",
       "  119,\n",
       "  133,\n",
       "  9304,\n",
       "  120,\n",
       "  135,\n",
       "  133,\n",
       "  9304,\n",
       "  120,\n",
       "  135,\n",
       "  146,\n",
       "  1202,\n",
       "  3254,\n",
       "  2354,\n",
       "  1181,\n",
       "  1103,\n",
       "  18992,\n",
       "  1111,\n",
       "  1103,\n",
       "  1864,\n",
       "  1115,\n",
       "  1251,\n",
       "  2673,\n",
       "  2602,\n",
       "  1107,\n",
       "  1103,\n",
       "  1273,\n",
       "  1110,\n",
       "  2602,\n",
       "  1111,\n",
       "  6037,\n",
       "  4998,\n",
       "  1897,\n",
       "  1190,\n",
       "  1198,\n",
       "  1106,\n",
       "  4900,\n",
       "  1234,\n",
       "  1105,\n",
       "  1294,\n",
       "  1948,\n",
       "  1106,\n",
       "  1129,\n",
       "  2602,\n",
       "  1107,\n",
       "  185,\n",
       "  8456,\n",
       "  9597,\n",
       "  13090,\n",
       "  1107,\n",
       "  1738,\n",
       "  119,\n",
       "  146,\n",
       "  6586,\n",
       "  140,\n",
       "  19556,\n",
       "  19368,\n",
       "  13329,\n",
       "  118,\n",
       "  162,\n",
       "  21678,\n",
       "  2162,\n",
       "  17056,\n",
       "  1110,\n",
       "  170,\n",
       "  1363,\n",
       "  1273,\n",
       "  1111,\n",
       "  2256,\n",
       "  5277,\n",
       "  1106,\n",
       "  2025,\n",
       "  1103,\n",
       "  6092,\n",
       "  1105,\n",
       "  15866,\n",
       "  113,\n",
       "  1185,\n",
       "  23609,\n",
       "  1179,\n",
       "  3005,\n",
       "  114,\n",
       "  1104,\n",
       "  3619,\n",
       "  7678,\n",
       "  119,\n",
       "  1252,\n",
       "  1541,\n",
       "  117,\n",
       "  1142,\n",
       "  1273,\n",
       "  2144,\n",
       "  112,\n",
       "  189,\n",
       "  1138,\n",
       "  1277,\n",
       "  1104,\n",
       "  170,\n",
       "  4928,\n",
       "  119,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Rd6shXtGNbo"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hask40c1HJ4f",
    "outputId": "fcad3bea-b604-47a2-d763-ad05d3c0fef0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=True,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=IntervalStrategy.EPOCH,\n",
       "eval_use_gather_object=False,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=None,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_revision=None,\n",
       "hub_strategy=HubStrategy.EVERY_SAVE,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=no,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=2e-05,\n",
       "length_column_name=length,\n",
       "liger_kernel_config=None,\n",
       "load_best_model_at_end=False,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=./results/runs/Dec03_14-04-41_43c2917ed0e8,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=IntervalStrategy.STEPS,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=SchedulerType.LINEAR,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=None,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=5,\n",
       "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=./results,\n",
       "overwrite_output_dir=False,\n",
       "parallelism_config=None,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=16,\n",
       "per_device_train_batch_size=16,\n",
       "prediction_loss_only=False,\n",
       "project=huggingface,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['wandb'],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=None,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=SaveStrategy.STEPS,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "trackio_space_id=trackio,\n",
       "use_cpu=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args= TrainingArguments(\n",
    "    output_dir='./results',           #output directory               #evaluate every epoch\n",
    "    eval_strategy= \"epoch\",\n",
    "    report_to=\"wandb\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "8960cc0334c84658bab5fffd320372da",
      "ed919fc48d3949eaa02104eeda6afa4d",
      "5e3404d347a94a0c9f3a439b56373569",
      "9ce2505ca7644cfb8b8d011803ed5d37",
      "858acb2442774968bf524c6e47c565ef",
      "117f6180132e4f1da423c4b6156074a6",
      "1da24ffc32824dc8a796b428766b20aa",
      "6fe8e2e2f51a45aca440369f4bc5e3c2",
      "f332d82467b24434a4815150ebfd39f2",
      "5b25c7fff5744425afface82b48d059f",
      "8111fc44481446989cf88849f16524db"
     ]
    },
    "id": "_Z8Dcl7NIoA-",
    "outputId": "d4dd18ff-7f34-4edb-bacd-5976bcbd0aea"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8960cc0334c84658bab5fffd320372da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model= AutoModelForSequenceClassification.from_pretrained('bert-base-cased',num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cptzpwai-xty",
    "outputId": "c655fddf-5b87-4382-c702-eb8843773f9e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdixitmadhavi12\u001b[0m (\u001b[33mdixitmadhavi12-shoolini-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "id": "4rdIuAP__dFf",
    "outputId": "3dc382e0-5501-44c4-b150-d39673e2c698"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251203_140530-seq0ph6l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/seq0ph6l' target=\"_blank\">cerulean-night-8</a></strong> to <a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning' target=\"_blank\">https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/seq0ph6l' target=\"_blank\">https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/seq0ph6l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/seq0ph6l?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x78d0655ca2a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"bert-finetuning\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "id": "-J1j7sSz_ix1",
    "outputId": "a2e4b924-2f2a-4da9-8380-80dcb0474d16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cerulean-night-8</strong> at: <a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/seq0ph6l' target=\"_blank\">https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/seq0ph6l</a><br> View project at: <a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning' target=\"_blank\">https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251203_140530-seq0ph6l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251203_140534-qjtlbcjt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/qjtlbcjt' target=\"_blank\">honest-breeze-9</a></strong> to <a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning' target=\"_blank\">https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/qjtlbcjt' target=\"_blank\">https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/qjtlbcjt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dixitmadhavi12-shoolini-university/bert-finetuning/runs/qjtlbcjt?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x78d0655c87a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"bert-finetuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XGNxB-t_5Cx"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKqZPBuUJSeQ"
   },
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer=Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHrV3NhKNt4T"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259
    },
    "id": "apMPVSnXJ5PR",
    "outputId": "8b639b29-b4b8-46dc-e88a-fb897ecfa462"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3837' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3837/7815 2:02:09 < 2:06:42, 0.52 it/s, Epoch 2.45/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>0.209583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.247200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4485' max='7815' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4485/7815 2:18:37 < 1:42:58, 0.54 it/s, Epoch 2.87/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.228300</td>\n",
       "      <td>0.209583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.247200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "PvxTpVZTLcLB",
    "outputId": "84b5e404-b67c-4c40-e929-0c086bf76fa6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1148' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1148/1563 09:20 < 03:22, 2.05 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 12:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0449143648147583,\n",
       " 'eval_model_preparation_time': 0.0028,\n",
       " 'eval_runtime': 766.3478,\n",
       " 'eval_samples_per_second': 32.622,\n",
       " 'eval_steps_per_second': 2.04}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQ8C5vpKre5m"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
